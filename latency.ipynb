{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"recordingDatabase.csv\", sep=\",\", header=0)\n",
    "\n",
    "# remove person 0 and person 23, because person 0 is the system and person 23 was not in the analysis\n",
    "\n",
    "df = df[(df[\"PersonID\"] != 0) & (df[\"PersonID\"] != 23)]\n",
    "same_as_next = (\n",
    "    (df[\"Role\"] == df[\"Role\"].shift(-1)) &\n",
    "    (df[\"TypeOfRecording\"] == df[\"TypeOfRecording\"].shift(-1)) &\n",
    "    (df[\"PersonID\"] == df[\"PersonID\"].shift(-1))\n",
    ")\n",
    "\n",
    "df = df[~same_as_next].copy()\n",
    "\n",
    "\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], dayfirst=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latency(df, role_from, type_from, role_to, type_to):\n",
    "    results = []\n",
    "    for pid, group_df in df.groupby(\"PersonID\"):\n",
    "        \n",
    "\n",
    "        df_from = group_df[(group_df[\"Role\"] == role_from) & \n",
    "                           (group_df[\"TypeOfRecording\"] == type_from)].copy()\n",
    "        df_to   = group_df[(group_df[\"Role\"] == role_to) & \n",
    "                           (group_df[\"TypeOfRecording\"] == type_to)].copy()\n",
    "        \n",
    "\n",
    "\n",
    "        df_from = df_from.sort_values(\"Timestamp\")\n",
    "        df_to   = df_to.sort_values(\"Timestamp\")\n",
    "\n",
    "        df_from = df_from.rename(columns={\"Timestamp\": \"Timestamp_from\"})\n",
    "        df_to = df_to.rename(columns={\"Timestamp\": \"Timestamp_to\"})\n",
    "\n",
    "        merged = pd.merge_asof(\n",
    "            df_from, \n",
    "            df_to,\n",
    "            left_on=\"Timestamp_from\",\n",
    "            right_on=\"Timestamp_to\",\n",
    "            by=\"PersonID\",\n",
    "            direction=\"forward\"\n",
    "        )\n",
    "        \n",
    "\n",
    "        merged[\"latency_seconds\"] = (\n",
    "            merged[\"Timestamp_to\"] - merged[\"Timestamp_from\"]\n",
    "        ).dt.total_seconds()\n",
    "\n",
    "        #remove line if latency is larger than 20 seconds because it may indicate system error\n",
    "        merged = merged[merged[\"latency_seconds\"] < 10]\n",
    "        results.append(merged[[\"PersonID\", \"Timestamp_to\", \"Timestamp_from\", \"latency_seconds\"]])\n",
    "\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values([\"PersonID\", \"Timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "lat_user_rec_stt = compute_latency(df, \n",
    "                                   role_from=\"User\", \n",
    "                                   type_from=\"Recording\", \n",
    "                                   role_to=\"User\", \n",
    "                                   type_to=\"STT\")\n",
    "print(\"=== User Recording → STT ===\")\n",
    "print(\"Durchschnitt:\", lat_user_rec_stt[\"latency_seconds\"].mean())\n",
    "print(\"Anzahl Werte:\", len(lat_user_rec_stt))\n",
    "print()\n",
    "\n",
    "# 3.2 User STT → Answer \n",
    "lat_sys_answer = compute_latency(df,\n",
    "                                 role_from=\"User\",\n",
    "                                 type_from=\"STT\",\n",
    "                                 role_to=\"Answer\",\n",
    "                                 type_to=\"TextCompletion\")\n",
    "print(\"=== User STT → Answer ===\")\n",
    "print(\"Durchschnitt:\", lat_sys_answer[\"latency_seconds\"].mean())\n",
    "print(\"Anzahl Werte:\", len(lat_sys_answer))\n",
    "print()\n",
    "\n",
    "# 3.3 Answer → TTS\n",
    "lat_answer_tts = compute_latency(df,\n",
    "                                 role_from=\"Answer\",\n",
    "                                 type_from=\"TextCompletion\",\n",
    "                                 role_to=\"Assistant\",\n",
    "                                 type_to=\"TTS\")\n",
    "print(\"=== Answer → TTS ===\")\n",
    "print(\"Durchschnitt:\", lat_answer_tts[\"latency_seconds\"].mean())\n",
    "print(\"Anzahl Werte:\", len(lat_answer_tts))\n",
    "print()\n",
    "\n",
    "print(\"=== Globale Statistik (Sekunden) ===\")\n",
    "for label, df_ in [\n",
    "    (\"UserRec→STT\", lat_user_rec_stt),\n",
    "    (\"SysTxt→Answer\", lat_sys_answer),\n",
    "    (\"Answer→TTS\", lat_answer_tts)\n",
    "]:\n",
    "    print(f\"{label}:\")\n",
    "    print(df_[\"latency_seconds\"].describe()) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "# remove PersonID 24 because there is no data\n",
    "df_ = df_[df_[\"PersonID\"] != 24]\n",
    "\n",
    "m = df_.groupby(\"PersonID\")[\"latency_seconds\"].mean()\n",
    "print(m)\n",
    "person_ids = m.index.tolist()\n",
    "\n",
    "diffs = []\n",
    "for (p1, p2) in itertools.combinations(person_ids, 2):\n",
    "    diffs.append(abs(m[p1] - m[p2]))\n",
    "avg_diff = np.mean(diffs)\n",
    "\n",
    "print(\"=== Average difference between persons ===\")\n",
    "print(avg_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
