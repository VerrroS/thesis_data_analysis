{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import wilcoxon, ttest_rel, shapiro, stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten Vorbereiten\n",
    "Importieren der Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionaires_raw = pl.read_csv(\"questionaires.csv\")\n",
    "question_results_raw = pl.read_csv(\"questionResults.csv\")\n",
    "test_condition_orders_raw = pl.read_csv(\"testConditionOrders.csv\")\n",
    "interaction_data_raw = pl.read_csv(\"recordingDatabase.csv\")\n",
    "fav = pl.read_csv(\"FAV.csv\")\n",
    "\n",
    "# drop rows where PersonID is = 0 or 23, because 0 was for testing and 23 did not do the learning evaluation\n",
    "questionaires = questionaires_raw.filter(pl.col(\"PersonID\") != 0).filter(pl.col(\"PersonID\") != 23)\n",
    "question_results = question_results_raw.filter(pl.col(\"PersonID\") != 0).filter(pl.col(\"PersonID\") != 23)\n",
    "test_condition_orders = test_condition_orders_raw.filter(pl.col(\"PersonID\") != 0).filter(pl.col(\"PersonID\") != 23)\n",
    "interaction_data = interaction_data_raw.filter(pl.col(\"PersonID\") != 0).filter(pl.col(\"PersonID\") != 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reihenfolgen Zählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_condition_orders_df = test_condition_orders.to_pandas()\n",
    "\n",
    "df_seq = test_condition_orders_df.groupby(\"PersonID\", sort=False)[\"Condition\"].apply(list).reset_index(name=\"ConditionSequence\")\n",
    "df_seq[\"ConditionSequenceTuple\"] = df_seq[\"ConditionSequence\"].apply(tuple)\n",
    "\n",
    "sequence_counts = df_seq[\"ConditionSequenceTuple\"].value_counts().reset_index()\n",
    "sequence_counts.columns = [\"ConditionSequenceTuple\", \"Anzahl\"]\n",
    "\n",
    "# print the whole dataframe\n",
    "print(tabulate(sequence_counts, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition der Skalen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define questions for the different scales/items\n",
    "\n",
    "efficiancy_questions = [\n",
    "    \"Zum Lernen empfinde ich die Anwendung als:\",\n",
    "]\n",
    "learning_question = [\n",
    "    \"Ich konnte gut mit dem LLM-Agenten lernen\",\n",
    "]\n",
    "\n",
    "information_question = [\n",
    "    \"Ich konnte die Informationen gut verstehen\",\n",
    "]\n",
    "\n",
    "stimulation_questions = [\n",
    "    \"Die Beschäftigung mit der Lernanwendung empfinde ich als:\",\n",
    "]\n",
    "visual_question = [\n",
    "    \"Die Gestaltung des LLM-Agenten hat mir gefallen\",\n",
    "]\n",
    "\n",
    "motivation_questions = [\n",
    "    \"Der LLM-Agent hat mich Motiviert\",\n",
    "]\n",
    "\n",
    "social_questions = [\n",
    "    \"Ich hatte das Gefühl mit einer Person in der virtuellen Umgebung zu interagieren statt mit einer Computer-Simulation\",\n",
    "]\n",
    "\n",
    "Sprachassistent = [\n",
    "    \"Die Antworten und Fragen des LLM-Agenten sind:\",\n",
    "]\n",
    "Nützlichkeit = [\n",
    "    \"Die Möglichkeit die Lernanwendung zu nutzen empfinde ich als:\",\n",
    "]\n",
    "Rolle_Motivator = [\n",
    "    \"Die Nennung des meines eigenen Namens während der Nutzung empfand ich als motivierend\",\n",
    "]\n",
    "Rolle_Organisator = [\n",
    "    \"Die Möglichkeit mir durch den LLM-Agenten Komponenten markieren zu lassen war nützlich\",\n",
    "]\n",
    "Rolle_Tutor = [\n",
    "    \"Durch die Abfrage des LLM Agenten konnte ich die Komponenten gut lernen\",\n",
    "]\n",
    "\n",
    "Rolle_Tutor2 = [\n",
    "    \"Die Zusammenfassung meiner Lernsession hat mir beim Lernen geholfen.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellen der Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### für gesamt UX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprachassistent-Score berechnen\n",
    "Antwortqualität = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(Sprachassistent))\n",
    "    .group_by([\"PersonID\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Antwortqualität\"))\n",
    " ).with_columns(\n",
    "     (pl.col(\"Antwortqualität\")/4).alias(\"Antwortqualität\")\n",
    "    )\n",
    "\n",
    "# Nützlichkeit-Score berechnen\n",
    "Nützlichkeit_df = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(Nützlichkeit))\n",
    "    .group_by([\"PersonID\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Nützlichkeit\"))\n",
    " ).with_columns(\n",
    "     (pl.col(\"Nützlichkeit\")/4).alias(\"Nützlichkeit\")\n",
    "     )\n",
    "\n",
    "# Rolle_Motivator-Score berechnen\n",
    "Rolle_Motivator_score = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(Rolle_Motivator))\n",
    "    .group_by([\"PersonID\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Rolle_Motivator_Score\"))\n",
    ")\n",
    "\n",
    "# Rolle_Organisator-Score berechnen\n",
    "Rolle_Organisator_score = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(Rolle_Organisator))\n",
    "    .group_by([\"PersonID\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Rolle_Organisator_Score\"))\n",
    ")\n",
    "\n",
    "# Rolle_Tutor-Score berechnen\n",
    "Rolle_Tutor_score = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(Rolle_Tutor))\n",
    "    .group_by([\"PersonID\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Rolle_Tutor_Score\"))\n",
    ")\n",
    "\n",
    "# Rolle_Tutor2-Score berechnen\n",
    "Rolle_Tutor2_score = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(Rolle_Tutor2))\n",
    "    .group_by([\"PersonID\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Rolle_Tutor2_Score\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### für Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficiancy_score = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(efficiancy_questions))\n",
    "    .group_by([\"PersonID\", \"Condition\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Efficiancy_Score\"))\n",
    " ).with_columns(\n",
    "     (pl.col(\"Efficiancy_Score\") / 4).alias(\"Effizienz Wertung\")\n",
    " )\n",
    "\n",
    "stimulation_score = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(stimulation_questions))\n",
    "    .group_by([\"PersonID\", \"Condition\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Stimulation_Score\"))\n",
    ").with_columns(\n",
    "    (pl.col(\"Stimulation_Score\") / 4).alias(\"Stimulations Wertung\")\n",
    ")\n",
    "\n",
    "Lerneffizienz = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(learning_question))\n",
    "    .group_by([\"PersonID\", \"Condition\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Lerneffizienz\"))\n",
    ")\n",
    "\n",
    "Informationsverständnis = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(information_question))\n",
    "    .group_by([\"PersonID\", \"Condition\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Informationsverständnis\"))\n",
    ")\n",
    "\n",
    "Gestaltung = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(visual_question))\n",
    "    .group_by([\"PersonID\", \"Condition\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Gestaltung\"))\n",
    ")\n",
    "\n",
    "social_score = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(social_questions))\n",
    "    .group_by([\"PersonID\", \"Condition\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Soziale Präsenz\"))\n",
    ")\n",
    "\n",
    "Motivation = (\n",
    "    questionaires.filter(pl.col(\"Question\").is_in(motivation_questions))\n",
    "    .group_by([\"PersonID\", \"Condition\"])\n",
    "    .agg((pl.col(\"Answer\").cast(float).sum()).alias(\"Motivation\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cronbachs Alpha für die einzelnen Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cronbach_alpha(df):\n",
    "    item_variances = df.var(axis=0, ddof=1)\n",
    "    total_variances = df.sum(axis=1).var(ddof=1)\n",
    "    number_of_items = len(item_variances)\n",
    "    return (number_of_items / (number_of_items - 1)) * (1 - item_variances.sum() / total_variances)\n",
    "\n",
    "def calculate_cronbach_for_conditions(df, conditions, scale_name):\n",
    "    for cond in conditions:\n",
    "        df_cond = df[df[\"Condition\"] == cond]\n",
    "        if df_cond.empty:\n",
    "            print(f\"Keine Daten für Condition: {cond}\")\n",
    "            continue\n",
    "        df_pivot = df_cond.pivot(index='PersonID', columns='left', values='Answer')\n",
    "        alpha = cronbach_alpha(df_pivot).round(2)\n",
    "        print(f\"Cronbach's Alpha for {scale_name} in {cond}: {alpha}\")\n",
    "\n",
    "\n",
    "# Definiere alle Conditions in einer Liste\n",
    "conditions_list = [\"ECA + Audio\", \"ECA + kein Audio\", \"UI + Audio\", \"UI + kein Audio\"]\n",
    "\n",
    "\n",
    "efficiancy_questions_df = questionaires.filter(pl.col(\"Question\").is_in(efficiancy_questions))\n",
    "efficiancy_questions_df = efficiancy_questions_df.drop(\"Question\", \"right\").to_pandas()\n",
    "\n",
    "calculate_cronbach_for_conditions(efficiancy_questions_df, conditions_list, \"Efficiancy\")\n",
    "\n",
    "stimulation_questions_df = questionaires.filter(pl.col(\"Question\").is_in(stimulation_questions))\n",
    "stimulation_questions_df = stimulation_questions_df.drop(\"Question\", \"right\").to_pandas()\n",
    "\n",
    "calculate_cronbach_for_conditions(stimulation_questions_df, conditions_list, \"Stimulation\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cronbachs Alpha für die Kombinierten Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_conditions = [\"ECA + Audio\", \"UI + Audio\"]\n",
    "df_combined = efficiancy_questions_df[efficiancy_questions_df[\"Condition\"].isin(combined_conditions)]\n",
    "\n",
    "df_combined = df_combined.groupby([\"PersonID\", \"left\"]).agg({\"Answer\": \"mean\"}).reset_index()\n",
    "df_pivot_combined = df_combined.pivot(index='PersonID', columns='left', values='Answer')\n",
    "alpha_combined = cronbach_alpha(df_pivot_combined)\n",
    "print(f\"Cronbach's Alpha for Efficiancy in {combined_conditions}: {alpha_combined}\")\n",
    "\n",
    "combined_conditions = [\"ECA + kein Audio\", \"UI + kein Audio\"]\n",
    "df_combined = efficiancy_questions_df[efficiancy_questions_df[\"Condition\"].isin(combined_conditions)]\n",
    "\n",
    "df_combined = df_combined.groupby([\"PersonID\", \"left\"]).agg({\"Answer\": \"mean\"}).reset_index()\n",
    "df_pivot_combined = df_combined.pivot(index='PersonID', columns='left', values='Answer')\n",
    "alpha_combined = cronbach_alpha(df_pivot_combined)\n",
    "print(f\"Cronbach's Alpha for Efficiancy in {combined_conditions}: {alpha_combined}\")\n",
    "\n",
    "combined_conditions = [\"ECA + Audio\", \"ECA + kein Audio\"]\n",
    "df_combined = efficiancy_questions_df[efficiancy_questions_df[\"Condition\"].isin(combined_conditions)]\n",
    "\n",
    "df_combined = df_combined.groupby([\"PersonID\", \"left\"]).agg({\"Answer\": \"mean\"}).reset_index()\n",
    "df_pivot_combined = df_combined.pivot(index='PersonID', columns='left', values='Answer')\n",
    "alpha_combined = cronbach_alpha(df_pivot_combined)\n",
    "print(f\"Cronbach's Alpha for Efficiancy in {combined_conditions}: {alpha_combined}\")\n",
    "\n",
    "combined_conditions = [\"UI + Audio\", \"UI + kein Audio\"]\n",
    "df_combined = efficiancy_questions_df[efficiancy_questions_df[\"Condition\"].isin(combined_conditions)]\n",
    "\n",
    "df_combined = df_combined.groupby([\"PersonID\", \"left\"]).agg({\"Answer\": \"mean\"}).reset_index()\n",
    "df_pivot_combined = df_combined.pivot(index='PersonID', columns='left', values='Answer')\n",
    "alpha_combined = cronbach_alpha(df_pivot_combined)\n",
    "print(f\"Cronbach's Alpha for Efficiancy in {combined_conditions}: {alpha_combined}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cronbachs Alpha für Nützlichkeit und Sprachassistent Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nützlichkeit\n",
    "nützlichkeit_questions_df = questionaires.filter(pl.col(\"Question\").is_in(Nützlichkeit))\n",
    "nützlichkeit_questions_df = nützlichkeit_questions_df.drop(\"Question\", \"right\").to_pandas()\n",
    "df_piviot_nützlichkeit = nützlichkeit_questions_df.pivot(index='PersonID', columns='left', values='Answer')\n",
    "\n",
    "cronbach_alpha_nützlichkeit = cronbach_alpha(df_piviot_nützlichkeit)\n",
    "\n",
    "# Sprachassistent\n",
    "Sprachassistent_questions_df = questionaires.filter(pl.col(\"Question\").is_in(Sprachassistent))\n",
    "Sprachassistent_questions_df = Sprachassistent_questions_df.drop(\"Question\", \"right\").to_pandas()\n",
    "df_piviot_Sprachassistent = Sprachassistent_questions_df.pivot(index='PersonID', columns='left', values='Answer')\n",
    "cronbach_alpha_Sprachassitent = cronbach_alpha(df_piviot_Sprachassistent)\n",
    "\n",
    "# print\n",
    "print(f\"Cronbach's Alpha for Nützlichkeit: {cronbach_alpha_nützlichkeit}\")\n",
    "print(f\"Cronbach's Alpha for Sprachassistent: {cronbach_alpha_Sprachassitent}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zusammenfügen der Scores in eine Tabelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gesamt UX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gesamtscores berechnen und zusammenführen\n",
    "final_ux_scores = (\n",
    "    Antwortqualität.join(Nützlichkeit_df, on=[\"PersonID\"], how=\"inner\")\n",
    "    .join(Rolle_Motivator_score, on=[\"PersonID\"], how=\"inner\")\n",
    "    .join(Rolle_Organisator_score, on=[\"PersonID\"], how=\"inner\")\n",
    "    .join(Rolle_Tutor_score, on=[\"PersonID\"], how=\"inner\")\n",
    "    .join(Rolle_Tutor2_score, on=[\"PersonID\"], how=\"inner\")\n",
    ")\n",
    "\n",
    "# Condition Tabelle erstellen\n",
    "condition_ux_scores = efficiancy_score.join(\n",
    "    stimulation_score, \n",
    "    on=[\"PersonID\", \"Condition\"], \n",
    "    how=\"inner\").join(social_score, \n",
    "    on=[\"PersonID\", \"Condition\"], \n",
    "    how=\"inner\").join(Motivation, \n",
    "    on=[\"PersonID\", \"Condition\"], \n",
    "    how=\"inner\").join(Lerneffizienz,\n",
    "    on=[\"PersonID\", \"Condition\"],\n",
    "    how=\"inner\").join(Gestaltung,\n",
    "    on=[\"PersonID\", \"Condition\"],\n",
    "    how=\"inner\").join(Informationsverständnis,\n",
    "    on=[\"PersonID\", \"Condition\"],\n",
    "    how=\"inner\")\n",
    "condition_ux_scores = condition_ux_scores.filter(pl.col(\"Condition\").is_not_null())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculeate combined UX Score for each person and condition\n",
    "condition_ux_scores = condition_ux_scores.with_columns(\n",
    "    (pl.col(\"Effizienz Wertung\").cast(float) + \n",
    "     pl.col(\"Stimulations Wertung\").cast(float)).alias(\"UX_Score\") \n",
    ")\n",
    "# ux score min max normalization\n",
    "condition_ux_scores = condition_ux_scores.with_columns(\n",
    "    ((pl.col(\"UX_Score\") - pl.col(\"UX_Score\").min()) / (pl.col(\"UX_Score\").max() - pl.col(\"UX_Score\").min())).alias(\"Normalized_UX_Score\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinzufügen der Testresults\n",
    "Jetzt werden zu der Condition Tabelle noch die Lernergebnisse hinzugefügt. Dafür werden zuerst die Tabellen vorbereitet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the PreTest questions\n",
    "question_results = question_results.filter(pl.col(\"TestCondition\").eq(\"PostTest\"))\n",
    "test_condition_orders = test_condition_orders_raw.unique()\n",
    "\n",
    "test_condition_orders_exploded = (\n",
    "    test_condition_orders.with_columns(\n",
    "        Components=pl.col(\"Components\").str.extract_all(r\"(\\d+)\")\n",
    "    )\n",
    "    .explode(\"Components\")\n",
    "    .with_columns(pl.col(\"Components\").cast(pl.Int64).alias(\"Component\"))\n",
    ").select(\"PersonID\", \"Condition\", \"Component\")\n",
    "\n",
    "# Entfernen von Duplikaten in test_condition_orders_exploded\n",
    "test_condition_orders_exploded = test_condition_orders_exploded.unique()\n",
    "\n",
    "# Entfernen von Duplikaten in question_results\n",
    "question_results = question_results.unique(subset=[\"PersonID\", \"CorrectComponent\", \"TestCondition\"])\n",
    "question_results.filter(question_results.is_duplicated())\n",
    "\n",
    "learning_results = question_results.join(\n",
    "    test_condition_orders_exploded,\n",
    "    left_on=[\"PersonID\", \"CorrectComponent\"],\n",
    "    right_on=[\"PersonID\", \"Component\"],\n",
    "    how=\"left\",\n",
    "    validate=\"1:1\",\n",
    ")\n",
    "\n",
    "assert learning_results[\"Condition\"].null_count() == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "und anschließend zusammengefügt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_ux_learning = learning_results.join(\n",
    "    condition_ux_scores,\n",
    "    on=[\"PersonID\", \"Condition\"],\n",
    "    how=\"inner\",\n",
    ").drop([\"TestCondition\",\"CorrectComponent\", \"SelectedComponent\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Füge Interaktionen hinzu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only count user interactions\n",
    "interaction_data = interaction_data_raw.filter(pl.col(\"Role\") == \"User\")\n",
    "\n",
    "# aggregation of the data so that each person and condition has one row, if a person has no interactions in a condition, put 0\n",
    "interaction_agg = interaction_data.group_by([\"PersonID\", \"Condition\"]).agg(\n",
    "    pl.count(\"PersonID\").alias(\"Interactions\")\n",
    ")\n",
    "\n",
    "\n",
    "# Join the interaction data with the final scores (left join because some people might not have interactions)\n",
    "conditions_ux_learning = conditions_ux_learning.join(\n",
    "    interaction_agg,\n",
    "    on=[\"PersonID\", \"Condition\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UX Scores, Combined UX Score, Testresult by Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation der Daten pro Person und Condition\n",
    "agg_df = conditions_ux_learning.group_by(['PersonID', 'Condition']).agg([\n",
    "    pl.mean(\"TestResult\").alias(\"TestResult\"),\n",
    "    pl.mean(\"Effizienz Wertung\").alias(\"Effizienz Wertung\"),\n",
    "    pl.mean(\"Stimulations Wertung\").alias(\"Stimulations Wertung\"),\n",
    "    pl.mean(\"Soziale Präsenz\").alias(\"Soziale Präsenz\"),\n",
    "    pl.mean(\"Motivation\").alias(\"Motivation\"),\n",
    "    pl.mean(\"Lerneffizienz\").alias(\"subjektiver Lernerfolg\"),\n",
    "    pl.mean(\"Gestaltung\").alias(\"Gestaltung\"),\n",
    "    pl.mean(\"Informationsverständnis\").alias(\"Informationsverständnis\"),\n",
    "    pl.mean(\"Normalized_UX_Score\").alias(\"UX_Score\")\n",
    "])\n",
    "\n",
    "# Liste der abhängigen Variablen\n",
    "variables = [\"TestResult\",\n",
    "                \"Effizienz Wertung\",\n",
    "                \"Stimulations Wertung\",\n",
    "                \"Soziale Präsenz\", \n",
    "                \"Motivation\",\n",
    "                \"subjektiver Lernerfolg\",\n",
    "                \"Gestaltung\",\n",
    "                \"Informationsverständnis\", \n",
    "                \"UX_Score\"]\n",
    "\n",
    "# Daten in langes Format bringen\n",
    "long_df = agg_df.unpivot(\n",
    "    index=[\"PersonID\", \"Condition\"],\n",
    "    on=variables,\n",
    "    variable_name=\"Variable\",\n",
    "    value_name=\"Value\"\n",
    ")\n",
    "\n",
    "# Berechnung der Statistiken\n",
    "stats_df = long_df.group_by([\"Variable\", \"Condition\"]).agg([\n",
    "    pl.median(\"Value\").alias(\"Median\").round(2),\n",
    "    pl.mean(\"Value\").alias(\"Mean\").round(2),\n",
    "    pl.std(\"Value\").alias(\"StdDev\").round(2),\n",
    "    pl.count(\"Value\").alias(\"Count\").round(2)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df_pd = stats_df.to_pandas()\n",
    "stats_df_pd = stats_df_pd.sort_values(by=[\"Variable\", \"Condition\"])\n",
    "\n",
    "# Um die mehrzeiligen Zeilen für die AV zu erstellen, fügen wir eine Spalte hinzu, die nur beim ersten Auftreten der AV den Namen enthält\n",
    "stats_df_pd['Variable_Label'] = stats_df_pd['Variable']\n",
    "stats_df_pd.loc[stats_df_pd.duplicated(subset=['Variable']), 'Variable_Label'] = ''\n",
    "\n",
    "\n",
    "# Reihenfolge der Spalten festlegen\n",
    "stats_df_pd_all = stats_df_pd[['Variable_Label', 'Condition', 'Median', 'Mean', 'StdDev', 'Count']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Styling Graphes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "my_pal = {\"ECA + Audio\": \"#F57C00\", \n",
    "          \"UI + Audio\": \"#00FFBB\", \n",
    "          \"ECA + kein Audio\": \"#652CB3\", \n",
    "          \"UI + kein Audio\": \"#4C8491\", \n",
    "          \"Audio\" : \"#FFFB00\", \n",
    "          \"Kein Audio\" : \"#79F824\",\n",
    "          \"ECA\" : \"#E80D1F\",\n",
    "          \"UI\" : \"#1e88e5\",\n",
    "          \"Antwortqualität\" : \"#484D6D\",\n",
    "          \"Nützlichkeit\" : \"#E7A977\",\n",
    "          \"Namensnennung\" : \"#95190C\",\n",
    "          \"Highlighting Funktion\" : \"#3EC300\",\n",
    "          \"Abfrage Funktion\" : \"#CEFF1A\",\n",
    "          \"Lernzusammenfassung\" : \"#C61E5E\",\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = long_df.filter(~pl.col(\"Variable\").is_in([\"UX_Score\", \n",
    "                                                   \"TestResult\", \n",
    "                                                    \"Effizienz Wertung\", \n",
    "                                                   \"Stimulations Wertung\"]))\n",
    "\n",
    "# order the conditions like that in dataframe order=[\"ECA + Audio\", \"ECA + kein Audio\", \"UI + Audio\", \"UI + kein Audio\",],\n",
    "new_df_pd = new_df.to_pandas()\n",
    "new_df_pd['Condition'] = pd.Categorical(new_df_pd['Condition'], [\"ECA + Audio\", \"ECA + kein Audio\", \"UI + Audio\", \"UI + kein Audio\"])\n",
    "sns.set(font_scale=2.6)\n",
    "\n",
    "#wrap labels to avoid overlapping\n",
    "new_df_pd[\"Variable\"] = new_df_pd[\"Variable\"].str.wrap(12)\n",
    "# make as barcharts and use mean and std as error bars\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.barplot(x=\"Value\", \n",
    "            y=\"Variable\", \n",
    "            hue=\"Condition\", \n",
    "            data=new_df_pd, \n",
    "            palette=my_pal,\n",
    "            capsize=.1,\n",
    "            errwidth=1,\n",
    "            errcolor=\"black\",\n",
    "            )\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kombinierte Conditions definieren\n",
    "combined_conditions_interface = {\n",
    "    \"ECA\": [\"ECA + Audio\", \"ECA + kein Audio\"],\n",
    "    \"UI\": [\"UI + Audio\", \"UI + kein Audio\"],\n",
    "}\n",
    "\n",
    "combined_conditions_Audio = {\n",
    "    \"Audio\": [\"ECA + Audio\", \"UI + Audio\"],\n",
    "    \"Kein Audio\": [\"ECA + kein Audio\", \"UI + kein Audio\"]\n",
    "}   \n",
    "\n",
    "# Neue Spalte für kombinierte Condition hinzufügen\n",
    "def map_combined_condition(row):\n",
    "    for combo_name, cond_list in combined_conditions_interface.items():\n",
    "        if row[\"Condition\"] in cond_list:\n",
    "            return combo_name\n",
    "    return row[\"Condition\"]\n",
    "\n",
    "def map_combined_condition_Audio(row):\n",
    "    for combo_name, cond_list in combined_conditions_Audio.items():\n",
    "        if row[\"Condition\"] in cond_list:\n",
    "            return combo_name\n",
    "    return row[\"Condition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter die relevanten Variablen und Originaldaten\n",
    "filtered_long_df = long_df.filter(pl.col(\"Variable\").is_in([\"UX_Score\"]))\n",
    "\n",
    "# Füge die kombinierten Conditions hinzu\n",
    "filtered_long_df_pd = filtered_long_df.to_pandas()\n",
    "\n",
    "# ---- 1. Boxplots für einzelne Conditions ----\n",
    "plt.figure(figsize=(24, 7\n",
    "                    ))\n",
    "ax = sns.barplot(\n",
    "    data=filtered_long_df_pd,\n",
    "    x=\"Value\", \n",
    "    y=\"Condition\",\n",
    "    #hue=\"Condition\",\n",
    "    palette=my_pal,\n",
    "    order=[\"ECA + Audio\", \"ECA + kein Audio\", \"UI + Audio\", \"UI + kein Audio\"],\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    ")\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print a table with the statistics\n",
    "print(tabulate(stats_df_pd_all, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter die relevanten Variablen und Originaldaten\n",
    "filtered_long_df = long_df.filter(pl.col(\"Variable\").is_in([\"Effizienz Wertung\"]))\n",
    "\n",
    "# make sure x axis has always values from 0 to 6\n",
    "plt.figure(figsize=(24, 7))\n",
    "sns.barplot(\n",
    "    data=filtered_long_df.to_pandas(),\n",
    "    x=\"Value\", \n",
    "    y=\"Condition\",\n",
    "    #hue=\"Condition\",\n",
    "    palette=my_pal,\n",
    "    order=[\"ECA + Audio\", \"ECA + kein Audio\", \"UI + Audio\", \"UI + kein Audio\"],\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    ")\n",
    "plt.xlim(0, 6.8)\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter die relevanten Variablen und Originaldaten\n",
    "filtered_long_df = long_df.filter(pl.col(\"Variable\").is_in([\"Stimulations Wertung\"]))\n",
    "\n",
    "# ---- 1. Boxplots für einzelne Conditions ----\n",
    "plt.figure(figsize=(24, 7))\n",
    "sns.barplot(\n",
    "    data=filtered_long_df.to_pandas(),\n",
    "    x=\"Value\", \n",
    "    y=\"Condition\",\n",
    "    #hue=\"Condition\",\n",
    "    palette=my_pal,\n",
    "    order=[\"ECA + Audio\",\"ECA + kein Audio\", \"UI + Audio\", \"UI + kein Audio\", ],\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    ")\n",
    "plt.xlim(0, 6.8)\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_long_df = long_df.filter(pl.col(\"Variable\").is_in([\"UX_Score\"]))\n",
    "\n",
    "filtered_long_df_pd = filtered_long_df.to_pandas()\n",
    "interface_combined = filtered_long_df_pd.copy()\n",
    "interface_combined[\"Combined_Condition\"] = filtered_long_df_pd.apply(map_combined_condition, axis=1)\n",
    "# select only the relevant columns\n",
    "interface_combined = interface_combined[[\"PersonID\", \"Combined_Condition\", \"Value\"]]\n",
    "interface_combined = interface_combined.groupby([\"PersonID\", \"Combined_Condition\"]).agg({\"Value\": \"mean\"}).reset_index()\n",
    "\n",
    "# Boxplots für kombinierte Conditions erstellen\n",
    "plt.figure(figsize=(24, 5))\n",
    "sns.barplot(\n",
    "    data=interface_combined,\n",
    "    x=\"Value\",\n",
    "    y=\"Combined_Condition\",\n",
    "    #hue=\"Combined_Condition\",\n",
    "    palette=my_pal,\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    ")\n",
    "plt.xlim(0, 1.1)\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Konvertierung nach Pandas und hinzufügen der Combined Condition\n",
    "Audio_combined = filtered_long_df_pd.copy()\n",
    "Audio_combined[\"Combined_Condition\"] = filtered_long_df_pd.apply(map_combined_condition_Audio, axis=1)\n",
    "# select only the relevant columns\n",
    "Audio_combined = Audio_combined[[\"PersonID\", \"Combined_Condition\", \"Value\"]]\n",
    "Audio_combined = Audio_combined.groupby([\"PersonID\", \"Combined_Condition\"]).agg({\"Value\": \"mean\"}).reset_index()\n",
    "\n",
    "# Boxplots für kombinierte Conditions erstellen\n",
    "plt.figure(figsize=(24, 5))\n",
    "sns.barplot(\n",
    "    data=Audio_combined,\n",
    "    x=\"Value\",\n",
    "    y=\"Combined_Condition\",\n",
    "    #hue=\"Combined_Condition\",\n",
    "    palette=my_pal,\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    ")\n",
    "plt.xlim(0, 1.1)\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Beispiel für interface_combined\n",
    "table_interface = (\n",
    "    interface_combined\n",
    "    .groupby(\"Combined_Condition\")[\"Value\"]\n",
    "    .agg([\"count\", \"mean\", \"std\", \"min\", \"max\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(table_interface)\n",
    "\n",
    "table_Audio = (\n",
    "    Audio_combined\n",
    "    .groupby(\"Combined_Condition\")[\"Value\"]\n",
    "    .agg([\"count\", \"mean\", \"std\", \"min\", \"max\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(table_Audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_long_df_testResult = long_df.filter(pl.col(\"Variable\").is_in([\"TestResult\"]))\n",
    "# make bar chart for TestResult\n",
    "plt.figure(figsize=(24, 7))\n",
    "sns.barplot(\n",
    "    data=filtered_long_df_testResult.to_pandas(),\n",
    "    x=\"Value\",\n",
    "    y=\"Condition\",\n",
    "    palette=my_pal,\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    "    order=[\"ECA + Audio\", \"ECA + kein Audio\", \"UI + Audio\", \"UI + kein Audio\"],\n",
    ")\n",
    "plt.xlabel(\"Wert\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Ersrtelle eine Tabelle mit den Testergebnissen\n",
    "table_testResult = (\n",
    "    filtered_long_df_testResult.to_pandas()\n",
    "    .groupby(\"Condition\")[\"Value\"]\n",
    "    .agg([\"count\", \"mean\", \"std\", \"min\", \"max\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(table_testResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bar chart for combined conditions\n",
    "\n",
    "Audio_combined_testResult = filtered_long_df_testResult.to_pandas().copy()\n",
    "Audio_combined_testResult[\"Combined_Condition\"] = Audio_combined_testResult.apply(map_combined_condition_Audio, axis=1)\n",
    "\n",
    "# select only the relevant columns\n",
    "Audio_combined_testResult = Audio_combined_testResult[[\"PersonID\", \"Combined_Condition\", \"Value\"]]\n",
    "Audio_combined_testResult = Audio_combined_testResult.groupby([\"PersonID\", \"Combined_Condition\"]).agg({\"Value\": \"mean\"}).reset_index()\n",
    "\n",
    "plt.figure(figsize=(24, 5))\n",
    "sns.barplot(\n",
    "    data=Audio_combined_testResult,\n",
    "    x=\"Value\",\n",
    "    y=\"Combined_Condition\",\n",
    "    palette=my_pal,\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    ")\n",
    "plt.xlim(0, 1.1)\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "interface_combined_testResult = filtered_long_df_testResult.to_pandas().copy()\n",
    "interface_combined_testResult[\"Combined_Condition\"] = interface_combined_testResult.apply(map_combined_condition, axis=1)\n",
    "# select only the relevant columns\n",
    "interface_combined_testResult = interface_combined_testResult[[\"PersonID\", \"Combined_Condition\", \"Value\"]]\n",
    "interface_combined_testResult = interface_combined_testResult.groupby([\"PersonID\", \"Combined_Condition\"]).agg({\"Value\": \"mean\"}).reset_index()\n",
    "# make bar chart for combined conditions\n",
    "plt.figure(figsize=(24,5 ))\n",
    "sns.barplot(\n",
    "    data=interface_combined_testResult,\n",
    "    x=\"Value\",\n",
    "    y=\"Combined_Condition\",\n",
    "    palette=my_pal,\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    ")\n",
    "plt.xlim(0, 1.1)\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabelle\n",
    "table_interface_testResult = (\n",
    "    interface_combined_testResult\n",
    "    .groupby(\"Combined_Condition\")[\"Value\"]\n",
    "    .agg([\"median\", \"mean\", \"std\", \"count\"]).round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "print(table_interface_testResult)\n",
    "\n",
    "table_Audio_testResult = (\n",
    "    Audio_combined_testResult\n",
    "    .groupby(\"Combined_Condition\")[\"Value\"]\n",
    "    .agg([\"median\", \"mean\", \"std\",\"count\"]).round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "print(table_Audio_testResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# beim fav datensatz, wenn \"ECA + Audio\" mach ECA, wenn \"UI + Audio\" mach UI\n",
    "fav_combined = fav.to_pandas()\n",
    "fav_combined[\"Favorite Condition\"] = fav_combined[\"Condition\"].apply(lambda x: \"ECA\" if x == \"ECA + Audio\" else \"UI\")\n",
    "fav_combined = fav_combined[[\"PersonID\", \"Favorite Condition\"]]\n",
    "\n",
    "df_wide = interface_combined_testResult.pivot(\n",
    "    index=\"PersonID\", \n",
    "    columns=\"Combined_Condition\", \n",
    "    values=\"Value\"\n",
    ")\n",
    "\n",
    "df_wide.head()\n",
    "\n",
    "\n",
    "pref = fav_combined.groupby('PersonID')['Favorite Condition'].first()\n",
    "\n",
    "\n",
    "df_wide = df_wide.join(pref, on='PersonID', how='left')\n",
    "df_wide.head()\n",
    "df_wide[\"Diff_UI_minus_ECA\"] = df_wide[\"UI\"] - df_wide[\"ECA\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_better_condition(row):\n",
    "    if row[\"Diff_UI_minus_ECA\"] > 0:\n",
    "        return \"UI\"\n",
    "    elif row[\"Diff_UI_minus_ECA\"] < 0:\n",
    "        return \"ECA\"\n",
    "    else:\n",
    "        return \"Equal\"\n",
    "\n",
    "df_wide[\"ActuallyBetter\"] = df_wide.apply(get_better_condition, axis=1)\n",
    "\n",
    "\n",
    "df_wide[\"PrefMatch\"] = (df_wide[\"Favorite Condition\"] == df_wide[\"ActuallyBetter\"])\n",
    "\n",
    "df_wide[\"PrefMatch\"].value_counts()\n",
    "pct_match = df_wide[\"PrefMatch\"].mean() * 100\n",
    "print(f\"{pct_match:.2f}% der Teilnehmenden haben die Bedingung bevorzugt, in der sie tatsächlich besser waren.\")\n",
    "df_wide.groupby(\"Favorite Condition\")[\"Diff_UI_minus_ECA\"].describe()\n",
    "\n",
    "crosstab = pd.crosstab(\n",
    "    df_wide[\"Favorite Condition\"],   # Zeilen\n",
    "    df_wide[\"ActuallyBetter\"]       # Spalten\n",
    ")\n",
    "print(crosstab)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions by Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interaction_stats = conditions_ux_learning.group_by(\"Condition\").agg(\n",
    "    pl.median(\"Interactions\").alias(\"Median\"),\n",
    "    pl.mean(\"Interactions\").alias(\"Mean\"),\n",
    "    pl.std(\"Interactions\").alias(\"StdDev\"),\n",
    "    pl.count(\"Interactions\").alias(\"Count\")\n",
    ")\n",
    "# round the values to 2 decimal places\n",
    "interaction_stats = interaction_stats.with_columns(\n",
    "    pl.col(\"Median\").round(2).alias(\"Median\"),\n",
    "    pl.col(\"Mean\").round(2).alias(\"Mean\"),\n",
    "    pl.col(\"StdDev\").round(2).alias(\"StdDev\")\n",
    ")\n",
    "print(interaction_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testresult by Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenhang zwischen häufigen Interaktionen und Testergebnissen\n",
    "interaction_test_ = conditions_ux_learning.select([\"Interactions\", \"TestResult\", \"PersonID\"]).to_pandas()\n",
    "# aggregate the data for the same person \n",
    "interaction_test_ = interaction_test_.groupby([\"PersonID\"]).agg({\n",
    "    \"Interactions\": \"mean\",\n",
    "    \"TestResult\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "interaction_test_correlation = interaction_test_.corr()\n",
    "print(interaction_test_correlation)\n",
    "\n",
    "\n",
    "interaction_ux_correlation = conditions_ux_learning.select([\"Interactions\", \"UX_Score\"]).to_pandas()\n",
    "interaction_ux_correlation = interaction_ux_correlation.corr()\n",
    "print(interaction_ux_correlation)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.scatterplot(\n",
    "    data=interaction_test_,\n",
    "    x=\"Interactions\",\n",
    "    y=\"TestResult\",\n",
    "    hue=\"Interactions\",\n",
    "    palette=\"Set2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gesamt UX Bewertung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregierte Ergebnisse ausgeben (Median, Mean, Min, Max, Std) und auf 2 Dezimalstellen runden\n",
    "# Liste der interessierenden Spalten\n",
    "columns = [col for col in final_ux_scores.columns if col != \"PersonID\"]\n",
    "\n",
    "# Berechnung der Statistiken\n",
    "stats = final_ux_scores.select([\n",
    "    getattr(pl.col(col), agg)().round(2).alias(f\"{agg}_{col}\")\n",
    "    for col in columns\n",
    "    for agg in [\"median\", \"mean\", \"std\"]\n",
    "])\n",
    "# Umstrukturieren der Tabelle\n",
    "tidy_stats = stats.transpose(include_header=True)\n",
    "tidy_stats = tidy_stats.rename({\"column\": \"Statistik\"}).with_columns(\n",
    "    pl.col(\"Statistik\").str.extract(r\"_(.+)$\").alias(\"Skala\")\n",
    ")\n",
    "\n",
    "print(tidy_stats.to_pandas().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertiere die Scores zu Pandas DataFrames\n",
    "Antwortqualität_pd = Antwortqualität.to_pandas()\n",
    "Nützlichkeit_pd = Nützlichkeit_df.to_pandas()\n",
    "\n",
    "# Füge eine Spalte hinzu, um den Score-Typ zu kennzeichnen\n",
    "Antwortqualität_pd['Score_Type'] = 'Antwortqualität'\n",
    "Nützlichkeit_pd['Score_Type'] = 'Nützlichkeit'\n",
    "\n",
    "# Benenne die Score-Spalte um, um sie zu vereinheitlichen\n",
    "Antwortqualität_pd = Antwortqualität_pd.rename(columns={'Antwortqualität': 'Score'})\n",
    "Nützlichkeit_pd = Nützlichkeit_pd.rename(columns={'Nützlichkeit': 'Score'})\n",
    "\n",
    "# Kombiniere die beiden DataFrames\n",
    "combined_scores = pd.concat([Antwortqualität_pd, Nützlichkeit_pd])\n",
    "\n",
    "\n",
    "# Erstelle einen BarChart\n",
    "plt.figure(figsize=(24,5))\n",
    "sns.barplot(\n",
    "    data=combined_scores,\n",
    "    x=\"Score\",\n",
    "    y=\"Score_Type\",\n",
    "    palette=my_pal,\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    ")\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n",
    "\n",
    "# tabelle\n",
    "table = (\n",
    "    combined_scores\n",
    "    .groupby(\"Score_Type\")[\"Score\"]\n",
    "    .agg([\"median\", \"mean\", \"std\", \"count\"]).round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplpt für die Rollen\n",
    "rolle_motivator_score_pd = Rolle_Motivator_score.to_pandas()\n",
    "rolle_organisator_score_pd = Rolle_Organisator_score.to_pandas()\n",
    "rolle_tutor_score_pd = Rolle_Tutor_score.to_pandas()\n",
    "rolle_tutor2_score_pd = Rolle_Tutor2_score.to_pandas()\n",
    "\n",
    "rolle_motivator_score_pd['Score_Type'] = 'Namensnennung'\n",
    "rolle_organisator_score_pd['Score_Type'] = 'Highlighting Funktion'\n",
    "rolle_tutor_score_pd['Score_Type'] = 'Abfrage Funktion'\n",
    "rolle_tutor2_score_pd['Score_Type'] = 'Lernzusammenfassung'\n",
    "\n",
    "rolle_motivator_score_pd = rolle_motivator_score_pd.rename(columns={'Rolle_Motivator_Score': 'Score'})\n",
    "rolle_organisator_score_pd = rolle_organisator_score_pd.rename(columns={'Rolle_Organisator_Score': 'Score'})\n",
    "rolle_tutor_score_pd = rolle_tutor_score_pd.rename(columns={'Rolle_Tutor_Score': 'Score'})\n",
    "rolle_tutor2_score_pd = rolle_tutor2_score_pd.rename(columns={'Rolle_Tutor2_Score': 'Score'})\n",
    "\n",
    "combined_scores = pd.concat([rolle_motivator_score_pd, rolle_organisator_score_pd, rolle_tutor_score_pd, rolle_tutor2_score_pd])\n",
    "\n",
    "# Erstelle einen BarChart\n",
    "plt.figure(figsize=(24, 7))\n",
    "sns.barplot(\n",
    "    data=combined_scores,\n",
    "    x=\"Score\",\n",
    "    y=\"Score_Type\",\n",
    "    palette=my_pal,\n",
    "    errorbar=\"sd\",\n",
    "    capsize=.1,\n",
    "    errwidth=1.5,\n",
    "    errcolor=\"black\",\n",
    ")\n",
    "plt.xlabel(\"Bewertung\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n",
    "\n",
    "# tabelle\n",
    "table = (\n",
    "    combined_scores\n",
    "    .groupby(\"Score_Type\")[\"Score\"]\n",
    "    .agg([\"median\", \"mean\", \"std\", \"count\"]).round(2)\n",
    "    .reset_index()\n",
    ")\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "fav = fav.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = fav[\"Condition\"].value_counts()\n",
    "labels = data.index\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.pie(data, \n",
    "        labels=labels, \n",
    "        autopct='%1.1f%%', \n",
    "        startangle=90,\n",
    "        colors=[\"#F57C00\", \"#00FFBB\", \"#4C8491\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signifikanztests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECA und UI und Lernerfolg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agg_df = learning_results.group_by(['PersonID', 'Condition']).agg([\n",
    "    pl.mean(\"TestResult\").alias(\"TestResult\"),\n",
    "])\n",
    "\n",
    "\n",
    "eval_data = (\n",
    "    agg_df.select(\"PersonID\", \"Condition\", \"TestResult\")\n",
    "    .with_columns(\n",
    "        Audio=pl.when(pl.col(\"Condition\").str.contains(\"kein Audio\"))\n",
    "        .then(pl.lit(\"kein Audio\"))\n",
    "        .otherwise(pl.lit(\"Audio\")),\n",
    "        Interface=pl.when(pl.col(\"Condition\").str.contains(\"UI\"))\n",
    "        .then(pl.lit(\"UI\"))\n",
    "        .otherwise(pl.lit(\"ECA\")),\n",
    "    )\n",
    "    .drop(\"Condition\")\n",
    ")\n",
    "df_model = eval_data.with_columns(\n",
    "    Audio_No_Audio=pl.when(pl.col(\"Audio\").eq(\"kein Audio\")).then(1).otherwise(0),\n",
    "    Interface_UI=pl.when(pl.col(\"Interface\").eq(\"UI\")).then(1).otherwise(0),\n",
    ").to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_aggregated = df_model.groupby([\"PersonID\", \"Interface\"]).agg({\"TestResult\": \"sum\"}).reset_index()\n",
    "\n",
    "print(df_aggregated.shape)\n",
    "\n",
    "stat, p = wilcoxon(\n",
    "    df_aggregated[df_aggregated[\"Interface\"] == \"UI\"][\"TestResult\"],\n",
    "    df_aggregated[df_aggregated[\"Interface\"] == \"ECA\"][\"TestResult\"],alternative='two-sided', mode ='auto'\n",
    ")\n",
    "\n",
    "print('Ungerichtet Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "stat, p = wilcoxon(\n",
    "    df_aggregated[df_aggregated[\"Interface\"] == \"UI\"][\"TestResult\"],\n",
    "    df_aggregated[df_aggregated[\"Interface\"] == \"ECA\"][\"TestResult\"],\n",
    "    alternative='greater', mode ='auto' # 'greater' für gerichtete Hypothese (UI > ECA)\n",
    ")\n",
    "\n",
    "print('Gerichtet (UI>ECA) Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "stat, p = wilcoxon(\n",
    "    df_aggregated[df_aggregated[\"Interface\"] == \"UI\"][\"TestResult\"],\n",
    "    df_aggregated[df_aggregated[\"Interface\"] == \"ECA\"][\"TestResult\"],\n",
    "    alternative='less', mode ='auto'  # 'greater' für gerichtete Hypothese (UI > ECA)\n",
    ")\n",
    "\n",
    "print('Gerichtet (ECA> UI)Statistics=%.3f, p=%.3f' % (stat, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio und Lernerfolg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_Audio = df_model.groupby([\"PersonID\", \"Audio\"]).agg({\"TestResult\": \"mean\"}).reset_index()\n",
    "# exact p-value calculations do not work with zeros, so we add 1 to all TestResults\n",
    "df_aggregated_Audio[\"TestResult\"] = df_aggregated_Audio[\"TestResult\"] + 1\n",
    "stat, p = wilcoxon(\n",
    "    df_aggregated_Audio[df_aggregated_Audio[\"Audio\"] == \"kein Audio\"][\"TestResult\"], \n",
    "    df_aggregated_Audio[df_aggregated_Audio[\"Audio\"] == \"Audio\"][\"TestResult\"],\n",
    "    alternative='greater'  # 'greater' für gerichtete Hypothese (kein Audio > Audio)\n",
    ")\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenhäge UX und Interface/Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = (\n",
    "    condition_ux_scores.select(\"PersonID\", \"Condition\", \"Efficiancy_Score\", \"Stimulation_Score\", \"Motivation\")\n",
    "    .with_columns(\n",
    "        Audio=pl.when(pl.col(\"Condition\").str.contains(\"kein Audio\"))\n",
    "        .then(pl.lit(\"kein Audio\"))\n",
    "        .otherwise(pl.lit(\"Audio\")),\n",
    "        Interface=pl.when(pl.col(\"Condition\").str.contains(\"UI\"))\n",
    "        .then(pl.lit(\"UI\"))\n",
    "        .otherwise(pl.lit(\"ECA\")),\n",
    "    )\n",
    "    .drop(\"Condition\")\n",
    ")\n",
    "\n",
    "# make a new colum UX Score and sum up the efficiancy, stimulation and motivation scores for each person\n",
    "eval_data1 = eval_data.with_columns(\n",
    "    (pl.col(\"Efficiancy_Score\") + pl.col(\"Stimulation_Score\") + pl.col(\"Motivation\")).alias(\"UX_Score\")\n",
    ").drop(\"Efficiancy_Score\", \"Stimulation_Score\", \"Motivation\")\n",
    "\n",
    "# now summerize the ux scores for the two interfaces for each person\n",
    "eval_data2 = eval_data1.group_by(\"PersonID\", \"Interface\").agg(\n",
    "    pl.sum(\"UX_Score\").alias(\"UX_Score\")\n",
    ")\n",
    "\n",
    "eval_data3 = eval_data1.group_by(\"PersonID\", \"Audio\").agg(\n",
    "    pl.sum(\"UX_Score\").alias(\"UX_Score\")\n",
    ")\n",
    "\n",
    "# drop UI \n",
    "eval_data4 = eval_data1.filter(pl.col(\"Interface\").eq(\"UI\")).drop(\"Interface\").group_by(\"PersonID\", \"Audio\").agg(\n",
    "    pl.sum(\"UX_Score\").alias(\"UX_Score\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalverteilung überprüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = eval_data2.to_pandas()\n",
    "df_Audio = eval_data3.to_pandas()\n",
    "df_ECA_Audio = eval_data4.to_pandas()\n",
    "# UX_Score-Werte pro Interface extrahieren\n",
    "eca_scores = df[df['Interface'] == 'ECA']['UX_Score']\n",
    "ui_scores = df[df['Interface'] == 'UI']['UX_Score']\n",
    "Audio_scores = df_Audio[df_Audio['Audio'] == 'Audio']['UX_Score']\n",
    "no_Audio_scores = df_Audio[df_Audio['Audio'] == 'kein Audio']['UX_Score']\n",
    "ECA_Audio_scores = df_ECA_Audio[df_ECA_Audio['Audio'] == 'Audio']['UX_Score']\n",
    "ECA_no_Audio_scores = df_ECA_Audio[df_ECA_Audio['Audio'] == 'kein Audio']['UX_Score']\n",
    "\n",
    "# Shapiro-Wilk-Test für ECA\n",
    "stat_eca, p_eca = shapiro(eca_scores)\n",
    "print('Shapiro-Wilk Test für ECA UX_Score: Statistik=%.3f, p=%.3f' % (stat_eca, p_eca))\n",
    "if p_eca > 0.05:\n",
    "    print('ECA UX_Score ist normalverteilt')\n",
    "else:\n",
    "    print('ECA UX_Score ist nicht normalverteilt')\n",
    "\n",
    "# Shapiro-Wilk-Test für UI\n",
    "stat_ui, p_ui = shapiro(ui_scores)\n",
    "print('Shapiro-Wilk Test für UI UX_Score: Statistik=%.3f, p=%.3f' % (stat_ui, p_ui))\n",
    "if p_ui > 0.05:\n",
    "    print('UI UX_Score ist normalverteilt')\n",
    "else:\n",
    "    print('UI UX_Score ist nicht normalverteilt')\n",
    "\n",
    "# Shapiro-Wilk-Test für Audio\n",
    "stat_Audio, p_Audio = shapiro(Audio_scores)\n",
    "print('Shapiro-Wilk Test für Audio UX_Score: Statistik=%.3f, p=%.3f' % (stat_Audio, p_Audio))\n",
    "if p_Audio > 0.05:\n",
    "    print('Audio UX_Score ist normalverteilt')\n",
    "else:\n",
    "    print('Audio UX_Score ist nicht normalverteilt')\n",
    "\n",
    "# Shapiro-Wilk-Test für kein Audio\n",
    "stat_no_Audio, p_no_Audio = shapiro(no_Audio_scores)\n",
    "print('Shapiro-Wilk Test für kein Audio UX_Score: Statistik=%.3f, p=%.3f' % (stat_no_Audio, p_no_Audio))\n",
    "if p_no_Audio > 0.05:\n",
    "    print('kein Audio UX_Score ist normalverteilt')\n",
    "else:\n",
    "    print('kein Audio UX_Score ist nicht normalverteilt')\n",
    "\n",
    "# Zusätzlich: Testen der Normalverteilung der Differenzen (UI - ECA) für einen gepaarten Vergleich\n",
    "# Pivotieren, um UI und ECA pro Person in einer Zeile zu haben\n",
    "df_pivot = df.pivot(index='PersonID', columns='Interface', values='UX_Score').dropna()\n",
    "\n",
    "# Berechnen der Differenzen (UI - ECA)\n",
    "differences_interface =  df_pivot['ECA'] - df_pivot['UI']\n",
    "\n",
    "# Shapiro-Wilk-Test für die Differenzen\n",
    "stat_diff, p_diff = shapiro(differences_interface)\n",
    "print('Shapiro-Wilk Test für Differenzen (UI - ECA) UX_Score: Statistik=%.3f, p=%.3f' % (stat_diff, p_diff))\n",
    "if p_diff > 0.05:\n",
    "    print('Die Differenzen sind normalverteilt')\n",
    "else:\n",
    "    print('Die Differenzen sind nicht normalverteilt')\n",
    "\n",
    "\n",
    "# Zusätzlich: Testen der Normalverteilung der Differenzen (Audio - kein Audio) für einen gepaarten Vergleich\n",
    "# Pivotieren, um Audio und kein Audio pro Person in einer Zeile zu haben\n",
    "df_pivot_Audio = df_Audio.pivot(index='PersonID', columns='Audio', values='UX_Score').dropna()\n",
    "\n",
    "# Berechnen der Differenzen (Audio - kein Audio)\n",
    "differences_Audio = df_pivot_Audio['Audio'] - df_pivot_Audio['kein Audio']\n",
    "\n",
    "# Shapiro-Wilk-Test für die Differenzen\n",
    "stat_diff_Audio, p_diff_Audio = shapiro(differences_Audio)\n",
    "print('Shapiro-Wilk Test für Differenzen (Audio - kein Audio) UX_Score: Statistik=%.3f, p=%.3f' % (stat_diff_Audio, p_diff_Audio))\n",
    "if p_diff_Audio > 0.05:\n",
    "    print('Die Differenzen sind normalverteilt')\n",
    "else:\n",
    "    print('Die Differenzen sind nicht normalverteilt')\n",
    "\n",
    "\n",
    "# Zusätzlich: Testen der Normalverteilung der Differenzen (ECA Audio - ECA kein Audio) für einen gepaarten Vergleich\n",
    "# Pivotieren, um Audio und kein Audio pro Person in einer Zeile zu haben\n",
    "df_pivot_ECA_Audio = df_ECA_Audio.pivot(index='PersonID', columns='Audio', values='UX_Score').dropna()\n",
    "\n",
    "# Berechnen der Differenzen (Audio - kein Audio)\n",
    "differences_ECA_Audio = df_pivot_ECA_Audio['Audio'] - df_pivot_ECA_Audio['kein Audio']\n",
    "\n",
    "# Shapiro-Wilk-Test für die Differenzen\n",
    "stat_diff_ECA_Audio, p_diff_ECA_Audio = shapiro(differences_ECA_Audio)\n",
    "print('Shapiro-Wilk Test für Differenzen (ECA Audio - ECA kein Audio) UX_Score: Statistik=%.3f, p=%.3f' % (stat_diff_ECA_Audio, p_diff_ECA_Audio))\n",
    "if p_diff_ECA_Audio > 0.05:\n",
    "    print('Die Differenzen sind normalverteilt')\n",
    "else:\n",
    "    print('Die Differenzen sind nicht normalverteilt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten für T-Tests vorbereiten\n",
    "eca_df = df[df['Interface'] == 'ECA'][['PersonID', 'UX_Score']].rename(columns={'UX_Score': 'ECA_UX_Score'})\n",
    "ui_df = df[df['Interface'] == 'UI'][['PersonID', 'UX_Score']].rename(columns={'UX_Score': 'UI_UX_Score'})\n",
    "\n",
    "Audio_df = df_Audio[df_Audio['Audio'] == 'Audio'][['PersonID', 'UX_Score']].rename(columns={'UX_Score': 'Audio_UX_Score'})\n",
    "no_Audio_df = df_Audio[df_Audio['Audio'] == 'kein Audio'][['PersonID', 'UX_Score']].rename(columns={'UX_Score': 'No_Audio_UX_Score'})\n",
    "\n",
    "eca_Audio_df = df_ECA_Audio[df_ECA_Audio['Audio'] == 'Audio'][['PersonID', 'UX_Score']].rename(columns={'UX_Score': 'ECA_Audio_UX_Score'})\n",
    "eca_no_Audio_df = df_ECA_Audio[df_ECA_Audio['Audio'] == 'kein Audio'][['PersonID', 'UX_Score']].rename(columns={'UX_Score': 'ECA_No_Audio_UX_Score'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gepaarter T-Test für Interface und UX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = wilcoxon(ui_scores,eca_scores, alternative='greater', mode ='auto')\n",
    "print('Gerichteter Wilcoxon-Test: Statistik=%.3f, p=%.3f' % (stat, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTest für Audio und UX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_t, p_t = ttest_rel(no_Audio_df['No_Audio_UX_Score'], Audio_df['Audio_UX_Score'], alternative='greater')\n",
    "print('Gerichteter t-Test für Audio > kein Audio: Statistik=%.3f, p=%.3f' % (stat_t, p_t))\n",
    "if p_t < 0.05:\n",
    "    print('Signifikanter Unterschied zwischen Audio und kein Audio UX_Scores (H0 wird verworfen)')\n",
    "else:\n",
    "    print('Kein signifikanter Unterschied zwischen Audio und kein Audio UX_Scores (H0 wird nicht verworfen)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTest für ECA Audio und ECA kein Audio und UX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerichteter t-Test für kein Audio > Audio\n",
    "stat_t, p_t = ttest_rel(eca_no_Audio_df['ECA_No_Audio_UX_Score'], eca_Audio_df['ECA_Audio_UX_Score'], alternative='greater')\n",
    "print('Gerichteter t-Test für ECA kein Audio < ECA Audio: Statistik=%.3f, p=%.3f' % (stat_t, p_t))\n",
    "if p_t < 0.05:\n",
    "    print('Signifikanter Unterschied zwischen Audio und kein Audio UX_Scores (H0 wird verworfen)')\n",
    "else:\n",
    "    print('Kein signifikanter Unterschied zwischen Audio und kein Audio UX_Scores (H0 wird nicht verworfen)')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spezifische Komponenten schwieriger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count if in the Testresults specific components are more often wrong than ot\n",
    "df_post_false = question_results.filter(pl.col(\"TestResult\").eq(\"false\"))\n",
    "# Nur falsche (false) im PostTest\n",
    "#df_post_false = question_results[question_results[\"TestResult\"] == \"false\"]\n",
    "print(df_post_false)\n",
    "df_post_false.to_pandas()\n",
    "\n",
    "counts_wrong = (\n",
    "    df_post_false\n",
    "    .group_by(\"CorrectComponent\")\n",
    "    .agg(pl.count(\"CorrectComponent\").alias(\"Fehlversuche\"))\n",
    "    .sort(\"Fehlversuche\")\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "print(counts_wrong)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wie oft kam jede richtige Komponente im PostTest überhaupt vor?\n",
    "df_post_total = (\n",
    "    question_results\n",
    "    .group_by(\"CorrectComponent\")\n",
    "    .agg(pl.count(\"CorrectComponent\").alias(\"Gesamt\"))\n",
    "    .sort(\"Gesamt\")\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "df_merged = pd.merge(counts_wrong, df_post_total, on=\"CorrectComponent\", how=\"outer\").fillna(0)\n",
    "# Fehlversuche / Gesamt\n",
    "df_merged[\"Fehlerrate\"] = df_merged[\"Fehlversuche\"] / df_merged[\"Gesamt\"]\n",
    "df_merged = df_merged.sort_values(by=\"Fehlerrate\", ascending=False)\n",
    "\n",
    "#print(df_merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verteilung der Komponenten in den Testbedingungen\n",
    "#print(test_condition_orders_exploded)\n",
    "\n",
    "counts_cond = (\n",
    "    test_condition_orders_exploded\n",
    "    .group_by( \"Condition\", \"Component\")\n",
    "    .agg(pl.count(\"Component\").alias(\"Count\"))\n",
    "    .sort(\"Count\")\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "#print(counts_cond)\n",
    "\n",
    "df_cond_total = pd.merge(\n",
    "    counts_cond, \n",
    "    counts_total, \n",
    "    on=\"Component\", \n",
    "    how=\"left\")\n",
    "\n",
    "#print(df_cond_total)\n",
    "\n",
    "#rename CorrectComponent to Component\n",
    "df_merged = df_merged.rename(columns={\"CorrectComponent\": \"Component\"})\n",
    "\n",
    "df_final = pd.merge(\n",
    "    df_cond_total, \n",
    "    df_merged, \n",
    "    on=\"Component\", \n",
    "    how=\"left\")\n",
    "\n",
    "df_final = df_final.fillna(0)\n",
    "\n",
    "\n",
    "# Sortieren nach Condition (z.B.) oder Fehlerrate\n",
    "df_final = df_final.sort_values(by=\"Condition\", ascending=True)\n",
    "#print the final table as a table\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = counts_cond.pivot(\n",
    "    index=\"Condition\",\n",
    "    columns=\"Component\",\n",
    "    values=\"Count\"\n",
    ")\n",
    "\n",
    "df_pivot = df_pivot.fillna(0)\n",
    "\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(df_pivot, annot=True, fmt=\".0f\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Komponenten\")\n",
    "plt.ylabel(\"Bedingungen\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"WeightedError\"] = df_final[\"Count\"] * df_final[\"Fehlerrate\"]\n",
    "\n",
    "# 2) Gruppierung: sum(WeightedError), sum(Count)\n",
    "df_weighted = (\n",
    "    df_final.groupby(\"Condition\", as_index=False)\n",
    "    .agg({\"WeightedError\": \"sum\", \"Count\": \"sum\"})\n",
    ")\n",
    "\n",
    "# 3) Gewichtete Fehlerrate: Sum(WeightedError) / Sum(Count)\n",
    "df_weighted[\"WeightedErrorRate\"] = df_weighted[\"WeightedError\"] / df_weighted[\"Count\"]\n",
    "\n",
    "print(df_weighted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
